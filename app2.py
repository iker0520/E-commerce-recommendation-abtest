import streamlit as st
import pandas as pd
import torch
import random
import os
import sys
import pickle
import numpy as np
import re
import glob

# ------------------------------------------------------------------
# 1. [í•„ìˆ˜] ëª¨ë“ˆ ê²½ë¡œ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ì§œ ë“±ë¡ (ì—ëŸ¬ ë°©ì§€)
# ------------------------------------------------------------------
import tisasrec_local
sys.modules['TiSASRec'] = tisasrec_local

from types import ModuleType
def mock_lib(name):
    if name not in sys.modules: sys.modules[name] = ModuleType(name)
    return sys.modules[name]

for lib in ['kmeans_pytorch', 'lightgbm', 'xgboost', 'ray', 'hyperopt', 'colorama']:
    mock_lib(lib)
    sys.modules[f"{lib}.sklearn"] = mock_lib(f"{lib}.sklearn")

if 'kmeans_pytorch' in sys.modules:
    sys.modules['kmeans_pytorch'].kmeans = lambda *args, **kwargs: (None, None)

import recbole
if not hasattr(recbole, 'utils'):
    recbole.utils = ModuleType('recbole.utils')
    sys.modules['recbole.utils'] = recbole.utils

if not hasattr(recbole.utils, 'enum_type'):
    m_enum = ModuleType('recbole.utils.enum_type')
    sys.modules['recbole.utils.enum_type'] = m_enum
    recbole.utils.enum_type = m_enum
    class Dummy:
        def __init__(self, *args, **kwargs): pass
    for cls in ['ModelType', 'DataLoaderType', 'KGDataLoaderState', 'EvaluatorType', 'InputType', 'FeatureType']:
        setattr(m_enum, cls, Dummy)

# ------------------------------------------------------------------
# 2. ë°ì´í„° ë° ëª¨ë¸ ë¡œë“œ
# ------------------------------------------------------------------
from recbole.model.sequential_recommender.sasrec import SASRec
from recbole.data.interaction import Interaction

DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class MockDataset:
    def __init__(self, n_items):
        self.n_items = n_items
    def num(self, field):
        return self.n_items

def load_translations():
    """ë²ˆì—­ íŒŒì¼ ë¡œë“œ ë° ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±"""
    csv_path = './data/translation_progress.csv'
    if not os.path.exists(csv_path):
        return {}, {}, {}
    
    try:
        df = pd.read_csv(csv_path)
        df['Original_English'] = df['Original_English'].astype(str).str.strip()
        df['Translated_Korean'] = df['Translated_Korean'].astype(str).str.strip()
        
        l1_df = df[df['Category_Type'] == 'ëŒ€ë¶„ë¥˜']
        l1_map = dict(zip(l1_df['Original_English'], l1_df['Translated_Korean']))
        
        l2_df = df[df['Category_Type'] == 'ì¤‘ë¶„ë¥˜']
        l2_map = dict(zip(l2_df['Original_English'], l2_df['Translated_Korean']))
        
        item_df = df[df['Category_Type'] == 'ì„ íƒ']
        item_map = dict(zip(item_df['Original_English'], item_df['Translated_Korean']))
        
        return l1_map, l2_map, item_map
    except Exception as e:
        st.error(f"ë²ˆì—­ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {}, {}, {}

@st.cache_data
def load_data():
    # 1. ë©”íƒ€ ë°ì´í„°
    try:
        all_df = pd.read_pickle('data/meta_lookup.pkl')
    except:
        st.error("data/meta_lookup.pkl íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None, None, None

    # 2. ë²ˆì—­ ë°ì´í„° ì ìš©
    l1_map, l2_map, item_map = load_translations()
    
    all_df['L1'] = all_df['L1'].astype(str).str.strip()
    all_df['L2'] = all_df['L2'].astype(str).str.strip()
    all_df['Item_Name'] = all_df['Item_Name'].astype(str).str.strip()

    all_df['L1_KR'] = all_df['L1'].map(l1_map).fillna(all_df['L1'])
    all_df['L2_KR'] = all_df['L2'].map(l2_map).fillna(all_df['L2'])
    all_df['Item_Name_KR'] = all_df['Item_Name'].map(item_map).fillna(all_df['Item_Name'])

    # 3. ë§¤í•‘ ë°ì´í„°
    try:
        with open("data/recbole_vocab.pkl", "rb") as f:
            vocab = pickle.load(f)
        token2id = vocab['token2id']
        id2token = vocab['id2token']
        
        if not isinstance(id2token, dict):
            id2token = {i: str(token) for i, token in enumerate(id2token)}
    except Exception as e:
        st.error(f"ë§¤í•‘ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None, None, None
        
    return all_df, token2id, id2token

@st.cache_data
def load_cycle_data():
    try:
        with open("data/item_cycle_lookup.pkl", "rb") as f:
            return pickle.load(f)
    except:
        return {} 

@st.cache_resource
def load_models():
    sas_path = 'data/SASRec-Nov-27-2025_10-12-11.pth'
    sas_model, sas_n_items = None, 0
    try:
        checkpoint = torch.load(sas_path, map_location=DEVICE, weights_only=False)
        sas_n_items = checkpoint['state_dict']['item_embedding.weight'].shape[0]
        sas_model = SASRec(checkpoint['config'], MockDataset(sas_n_items)).to(DEVICE)
        sas_model.load_state_dict(checkpoint['state_dict'])
        sas_model.eval()
        maxlen = checkpoint['config']['MAX_ITEM_LIST_LENGTH']
    except Exception as e:
        st.warning(f"SASRec ë¡œë“œ ì‹¤íŒ¨: {e}")
        maxlen = 50

    return sas_model, sas_n_items, maxlen

# ------------------------------------------------------------------
# 3. í˜ë¥´ì†Œë‚˜ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
# ------------------------------------------------------------------
def load_persona_history(all_df, filename):
    persona_path = os.path.join('data', 'personas', filename)
    
    if not os.path.exists(persona_path):
        st.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {persona_path}")
        return []

    try:
        try:
            df = pd.read_csv(persona_path, encoding='utf-8')
        except UnicodeDecodeError:
            df = pd.read_csv(persona_path, encoding='cp949')

        history = []
        for _, row in df.iterrows():
            days_str = str(row.get('ì‹œì ', '0'))
            days_match = re.search(r'\d+', days_str)
            days = int(days_match.group()) if days_match else 0
            
            item_name_raw = row.get('ìƒí’ˆ ì„ íƒ') or row.get('name')
            if not item_name_raw: continue

            matched_row = all_df[all_df['Item_Name'] == item_name_raw]
            
            if not matched_row.empty:
                item_id = str(matched_row.iloc[0]['item_id'])
                item_name_kr = matched_row.iloc[0]['Item_Name_KR']
                history.append({
                    'item_id': item_id,
                    'name': item_name_kr,
                    'days_ago': days
                })
            else:
                pass 
                
        return history
    except Exception as e:
        st.error(f"í˜ë¥´ì†Œë‚˜ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        return []

# ------------------------------------------------------------------
# 4. ë¡œì§ í•¨ìˆ˜ (Cycle Filtering)
# ------------------------------------------------------------------
def check_cycle_filtering(days_ago, cycle_info):
    if not cycle_info: return days_ago < 7
    p10 = cycle_info.get('p10', 0)
    p25 = cycle_info.get('p25', 0)
    
    if days_ago < p10: return random.random() < 1
    elif p10 <= days_ago < p25: return random.random() < 0.5
    else: return False

# ------------------------------------------------------------------
# 5. ë©”ì¸ ë¡œì§
# ------------------------------------------------------------------
def main():
    st.set_page_config(layout="wide", page_title="Recommendation Rule A/B Test")
    st.title("ğŸ›ï¸ ì‡¼í•‘ íŒ¨í„´ ê¸°ë°˜ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ A/B Test")

    all_df, token2id, id2token = load_data()
    if all_df is None: return
    
    cycle_data = load_cycle_data()
    sas_model, safe_n_items, maxlen = load_models()

    valid_tokens = [t for t, i in token2id.items() if i < safe_n_items]
    ui_df = all_df[all_df['item_id'].astype(str).isin(valid_tokens) & (all_df['purchase_count'] >= 10)].copy()

    if 'history' not in st.session_state: st.session_state['history'] = []

    # ---------------- Sidebar ----------------
    st.sidebar.header("ğŸ›’ êµ¬ë§¤ ì´ë ¥ êµ¬ì„±")
    
    # [1] í˜ë¥´ì†Œë‚˜ ì„ íƒ
    st.sidebar.subheader("1. í˜ë¥´ì†Œë‚˜ ì„ íƒ")
    persona_dir = os.path.join('data', 'personas')
    if not os.path.exists(persona_dir): os.makedirs(persona_dir, exist_ok=True)
        
    persona_files = [f for f in os.listdir(persona_dir) if f.endswith('.csv')]
    options = ["ì§ì ‘ ì…ë ¥ (ì„ íƒ ì•ˆ í•¨)"] + persona_files
    
    # .csv ì œê±°
    selected_persona = st.sidebar.selectbox(
        "í…ŒìŠ¤í„° ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”:", 
        options,
        format_func=lambda x: x.replace(".csv", "") if x != "ì§ì ‘ ì…ë ¥ (ì„ íƒ ì•ˆ í•¨)" else x
    )
    
    if selected_persona != "ì§ì ‘ ì…ë ¥ (ì„ íƒ ì•ˆ í•¨)":
        if st.sidebar.button("ğŸ“‚ ì„ íƒí•œ í˜ë¥´ì†Œë‚˜ ë¶ˆëŸ¬ì˜¤ê¸°"):
            persona_history = load_persona_history(all_df, selected_persona)
            if persona_history:
                st.session_state['history'] = persona_history
                st.session_state['history'].sort(key=lambda x: x['days_ago'], reverse=True)
                st.success(f"'{selected_persona.replace('.csv','')}' ë¡œë“œ ì™„ë£Œ!")
                st.session_state.pop('raw_scores', None)
                st.session_state.pop('ab_mapping', None)
                st.rerun()

    st.sidebar.divider()

    # [2] ì§ì ‘ ì¶”ê°€
    st.sidebar.subheader("2. ì•„ì´í…œ ì¶”ê°€")
    if not ui_df.empty:
        l1_list = sorted(ui_df['L1_KR'].unique())
        l1 = st.sidebar.selectbox("ëŒ€ë¶„ë¥˜", l1_list)
        
        l1_mask = ui_df['L1_KR'] == l1
        l2_list = sorted(ui_df[l1_mask]['L2_KR'].unique())
        l2 = st.sidebar.selectbox("ì¤‘ë¶„ë¥˜", l2_list)
        
        items = ui_df[l1_mask & (ui_df['L2_KR'] == l2)].sort_values(by='purchase_count', ascending=False)
        
        # êµ¬ë§¤íšŸìˆ˜ ì œê±°, ìƒí’ˆëª…ë§Œ í‘œì‹œ
        sel_item = st.sidebar.selectbox(
            "ìƒí’ˆ ì„ íƒ", 
            options=items.to_dict('records'), 
            format_func=lambda x: x['Item_Name_KR']
        )

        days = st.sidebar.number_input("ë©°ì¹  ì „ êµ¬ë§¤?", 0, 365, 0)
        
        if st.sidebar.button("â• ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€"):
            st.session_state['history'].append({
                'item_id': str(sel_item['item_id']),
                'name': sel_item['Item_Name_KR'],
                'days_ago': days
            })
            st.session_state['history'].sort(key=lambda x: x['days_ago'], reverse=True)
            st.rerun()

    if st.sidebar.button("ğŸ—‘ï¸ ì „ì²´ ì´ˆê¸°í™”"):
        st.session_state['history'] = []
        st.session_state.pop('raw_scores', None) 
        st.session_state.pop('ab_mapping', None) 
        st.rerun()

    # --- Main: ì‹œí€€ìŠ¤ í™•ì¸ ---
    st.subheader("ğŸ“‹ ì´ì»¤ë¨¸ìŠ¤ ìƒí’ˆ êµ¬ë§¤ ë‚´ì—­")
    st.info("""
        í…ŒìŠ¤í„°ë‹˜ì´ ì§ì ‘ êµ¬ë§¤ íˆìŠ¤í† ë¦¬ë¥¼ êµ¬ì„±í•˜ë©´, êµ¬ë§¤ì£¼ê¸°ë¥¼ ê³ ë ¤í•œ ì¶”ì²œê³¼ ê·¸ë ‡ì§€ ì•Šì€ ì¶”ì²œ ê²°ê³¼ê°€ ì œê³µë©ë‹ˆë‹¤.

        ìµœëŒ€í•œ ë³¸ì¸ì˜ ì‹¤ì œ êµ¬ë§¤íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹œí€€ìŠ¤ë¥¼ ììœ ë¡­ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”!

        ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ íŠ¹ì • í˜ë¥´ì†Œë‚˜ë¥¼ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜, ì§ì ‘ ì•„ì´í…œì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """)
    
    if not st.session_state['history']:
        st.info("""
        ì‹œí€€ìŠ¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.
        """)
    else:
        st.markdown("---")
        for i, item in enumerate(st.session_state['history']):
            col1, col2, col3 = st.columns([1, 6, 1])
            time_str = "ì˜¤ëŠ˜" if item['days_ago'] == 0 else f"{item['days_ago']}ì¼ ì „"
            
            with col1: st.caption(time_str)
            with col2: st.write(f"**{item['name']}**")
            with col3:
                # ê°œë³„ ì‚­ì œ ê¸°ëŠ¥
                if st.button("âŒ", key=f"del_{i}"):
                    st.session_state['history'].pop(i)
                    st.session_state.pop('raw_scores', None) 
                    st.session_state.pop('ab_mapping', None)
                    st.rerun()
        st.markdown("---")
    
        # alpha ê³ ì •
        alpha = 2.0 
        
        # ------------------------------------------------------------------
        # ì¶”ë¡  ë²„íŠ¼
        # ------------------------------------------------------------------
        if st.button("ğŸš€ ì¶”ì²œ ê²°ê³¼ ìƒì„±", type="primary"):
            if len(st.session_state['history']) < 2:
                st.warning("ì•„ì´í…œì„ 2ê°œ ì´ìƒ ë„£ì–´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("AI ë¶„ì„ ì¤‘..."):
                    if 'ab_mapping' in st.session_state:
                        del st.session_state['ab_mapping']
                    
                    hist_ids = []
                    for h in st.session_state['history']:
                        if h['item_id'] in token2id:
                            internal_id = token2id[h['item_id']]
                            if internal_id < safe_n_items:
                                hist_ids.append(internal_id)
                    
                    if not hist_ids: st.stop()
                        
                    seq_ids = hist_ids[-maxlen:]
                    pad_len = maxlen - len(seq_ids)
                    input_ids = [0] * pad_len + seq_ids
                    
                    item_seq = torch.LongTensor([input_ids]).to(DEVICE)
                    item_len = torch.LongTensor([maxlen]).to(DEVICE)

                    if sas_model:
                        inter_sas = Interaction({'item_id_list': item_seq, 'item_length': item_len})
                        raw_scores = sas_model.full_sort_predict(inter_sas).detach().cpu().numpy()[0]
                        
                        st.session_state['raw_scores'] = raw_scores
                        st.session_state['has_run'] = True
                        st.session_state['experiment_submitted'] = False

    # ------------------------------------------------------------------
    # ê²°ê³¼ ë Œë”ë§
    # ------------------------------------------------------------------
    if st.session_state.get('has_run', False) and 'raw_scores' in st.session_state:
        raw_scores = st.session_state['raw_scores']
        
        # --- Logic A: History Boost ---
        scores_A = raw_scores.copy()
        item_counts = {}
        for h in st.session_state['history']:
            raw_id = h['item_id']
            item_counts[raw_id] = item_counts.get(raw_id, 0) + 1
            
        for raw_id, count in item_counts.items():
            if raw_id in token2id:
                idx = token2id[raw_id]
                if idx < len(scores_A):
                    scores_A[idx] += alpha * np.log1p(count)

        topk_A_ids = np.argsort(scores_A)[::-1][:10]

        # --- Logic B: Cycle Filtering ---
        scores_B = scores_A.copy()
        
        for h in st.session_state['history']:
            raw_id = h['item_id']
            days = h['days_ago']
            if raw_id in token2id:
                idx = token2id[raw_id]
                if idx < len(scores_B):
                    c_info = cycle_data.get(raw_id, {})
                    if check_cycle_filtering(days, c_info):
                        scores_B[idx] = -np.inf
        
        topk_B_ids = np.argsort(scores_B)[::-1][:10]

        # --- ë§¤í•‘ ë¡œì§ ---
        if 'ab_mapping' not in st.session_state:
            st.session_state['ab_mapping'] = random.choice(['A_is_1', 'B_is_1'])

        mapping = st.session_state['ab_mapping']
        
        if mapping == 'A_is_1':
            opt1_ids, opt1_name = topk_A_ids, "Logic A (êµ¬ë§¤ì£¼ê¸° ê³ ë ¤ x)"
            opt2_ids, opt2_name = topk_B_ids, "Logic B (êµ¬ë§¤ì£¼ê¸° ê³ ë ¤ o (í•„í„°ë§))"
        else:
            opt1_ids, opt1_name = topk_B_ids, "Logic B (êµ¬ë§¤ì£¼ê¸° ê³ ë ¤ o (í•„í„°ë§))"
            opt2_ids, opt2_name = topk_A_ids, "Logic A (êµ¬ë§¤ì£¼ê¸° ê³ ë ¤ x)"

        def get_simple_info(idx):
            name, cat = "Unknown", ""
            if idx in id2token:
                raw_id = id2token[idx]
                row = all_df[all_df['item_id'].astype(str) == raw_id]
                if not row.empty:
                    name = row.iloc[0]['Item_Name_KR']
                    cat = row.iloc[0]['L2_KR']
            return f"[{cat}] {name}"

        st.divider()
        st.subheader("âš–ï¸ ë¸”ë¼ì¸ë“œ í…ŒìŠ¤íŠ¸: ë” ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì¶”ì²œì€?")
        
        bc1, bc2 = st.columns(2)
        with bc1:
            st.markdown("### ğŸ…°ï¸ Option 1")
            for rank, idx in enumerate(opt1_ids):
                if idx == 0: continue
                st.write(f"{rank+1}. {get_simple_info(idx)}")

        with bc2:
            st.markdown("### ğŸ…±ï¸ Option 2")
            for rank, idx in enumerate(opt2_ids):
                if idx == 0: continue
                st.write(f"{rank+1}. {get_simple_info(idx)}")

        st.markdown("---")
        with st.form("ab_test_form"):
            st.write("ğŸ“ **í‰ê°€ ì…ë ¥**")
            choice = st.radio("ë” ë§ˆìŒì— ë“œëŠ” ì¶”ì²œ ê²°ê³¼ëŠ”?", ["Option 1", "Option 2"], horizontal=True)
            reason = st.text_area("ì´ìœ :")
            
            if st.form_submit_button("ì œì¶œ ë° ê²°ê³¼ í™•ì¸", type="primary"):
                st.session_state['experiment_submitted'] = True
                st.session_state['user_choice'] = choice
                
                log_data = {
                    "timestamp": pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),
                    "user_choice": choice,
                    "logic_left": opt1_name,
                    "logic_right": opt2_name,
                    "winner": opt1_name if choice == "Option 1" else opt2_name,
                    "reason": reason
                }
                
                save_df = pd.DataFrame([log_data])
                csv_file = 'ab_test_results.csv'
                try:
                    if not os.path.exists(csv_file):
                        save_df.to_csv(csv_file, index=False, encoding='utf-8-sig')
                    else:
                        save_df.to_csv(csv_file, index=False, header=False, mode='a', encoding='utf-8-sig')
                    st.success("ë°ì´í„° ì €ì¥ ì™„ë£Œ!")
                except Exception as e:
                    st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

        # ------------------------------------------------------------------
        # ê²°ê³¼ ê³µê°œ ë° ìƒ‰ìƒ ê°•ì¡°
        # ------------------------------------------------------------------
        if st.session_state.get('experiment_submitted', False):
            st.divider()
            st.header("ğŸ”“ ê²°ê³¼ ê³µê°œ")
            
            user_pick = st.session_state['user_choice']
            real_logic = opt1_name if user_pick == "Option 1" else opt2_name
            
            st.success(f"ë‹¹ì‹ ì˜ ì„ íƒ: **{user_pick}**")
            st.info(f"ì‹¤ì œ ë¡œì§: **{real_logic}**")
            
            # ë¹„êµë¥¼ ìœ„í•œ ì§‘í•© ìƒì„±
            set_A = set(topk_A_ids)
            set_B = set(topk_B_ids)

            # [New] êµ¬ë§¤ ì´ë ¥ ì¡°íšŒìš© ë”•ì…”ë„ˆë¦¬ ìƒì„± (item_id -> ê°€ì¥ ìµœê·¼ days_ago)
            history_last_days = {}
            for h in st.session_state['history']:
                rid = str(h['item_id'])
                d = h['days_ago']
                # ê°™ì€ ì•„ì´í…œì´ ì—¬ëŸ¬ ë²ˆ ìˆì„ ê²½ìš° ê°€ì¥ ìµœê·¼(ì‘ì€ ìˆ«ì) ì €ì¥
                if rid not in history_last_days or d < history_last_days[rid]:
                    history_last_days[rid] = d

            rc1, rc2 = st.columns(2)
            
            # zipìœ¼ë¡œ ì¤‘ë³µ ì½”ë“œ í†µí•©
            for col, ids, name in zip([rc1, rc2], [opt1_ids, opt2_ids], [opt1_name, opt2_name]):
                with col:
                    st.markdown(f"### {name}")
                    for rank, idx in enumerate(ids):
                        if idx == 0: continue
                        
                        info = get_simple_info(idx)
                        
                        # [New] êµ¬ë§¤ ì´ë ¥ í™•ì¸ ë° í…ìŠ¤íŠ¸ ì¶”ê°€
                        raw_id = id2token.get(idx, None)
                        # [ìˆ˜ì • í›„: ì‹ ê·œ ìƒí’ˆ íƒœê·¸ ì¶”ê°€]
                        if raw_id and str(raw_id) in history_last_days:
                            last_day = history_last_days[str(raw_id)]
                            day_str = "ì˜¤ëŠ˜" if last_day == 0 else f"{last_day}ì¼ ì „"
                            info += f" **(â†» {day_str} êµ¬ë§¤)**"
                        else:
                        # êµ¬ë§¤ ê¸°ë¡ì´ ì—†ëŠ” ê²½ìš°
                            info += " **(âœ¨ ì‹ ê·œ ì¶”ì²œ)**"
                        

                        if name.startswith("Logic A"):
                            # Logic A ëª©ë¡: Logic Bì— ì—†ëŠ” ì•„ì´í…œ (ì‚¬ë¼ì§) -> ì£¼í™©ìƒ‰
                            if idx not in set_B:
                                st.markdown(f":orange[{rank+1}. {info}]")
                            else:
                                st.write(f"{rank+1}. {info}")
                        else:
                            # Logic B ëª©ë¡: Logic Aì— ì—†ëŠ” ì•„ì´í…œ (ìƒˆë¡œ ë“±ì¥) -> ì´ˆë¡ìƒ‰
                            if idx not in set_A:
                                st.markdown(f":green[{rank+1}. {info}]")
                            else:
                                st.write(f"{rank+1}. {info}")

if __name__ == "__main__":
    main()