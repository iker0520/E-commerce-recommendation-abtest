import streamlit as st
import pandas as pd
import torch
import random
import os
import sys
import pickle
import numpy as np
from streamlit_gsheets import GSheetsConnection

# ------------------------------------------------------------------
# 1. [í•„ìˆ˜] ëª¨ë“ˆ ê²½ë¡œ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ì§œ ë“±ë¡ (ì—ëŸ¬ ë°©ì§€)
# ------------------------------------------------------------------
import tisasrec_local
sys.modules['TiSASRec'] = tisasrec_local

# RecBole ì˜ì¡´ì„± ë¬¸ì œ í•´ê²° (recover_map.pyì™€ ë™ì¼í•œ ë°©ì‹)
from types import ModuleType
def mock_lib(name):
    if name not in sys.modules: sys.modules[name] = ModuleType(name)
    return sys.modules[name]

for lib in ['kmeans_pytorch', 'lightgbm', 'xgboost', 'ray', 'hyperopt', 'colorama']:
    mock_lib(lib)
    sys.modules[f"{lib}.sklearn"] = mock_lib(f"{lib}.sklearn")

if 'kmeans_pytorch' in sys.modules:
    sys.modules['kmeans_pytorch'].kmeans = lambda *args, **kwargs: (None, None)

# ------------------------------------------------------------------
# 2. ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ
# ------------------------------------------------------------------
from recbole.model.sequential_recommender.sasrec import SASRec
from tisasrec_local import TiSASRec
from recbole.data.interaction import Interaction
from utils import get_tisasrec_input

DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class MockDataset:
    def __init__(self, n_items):
        self.n_items = n_items
    def num(self, field):
        return self.n_items

@st.cache_data
def load_data():
    # 1. ë©”íƒ€ ë°ì´í„° (ìƒí’ˆëª…)
    try:
        all_df = pd.read_pickle('data/meta_lookup.pkl')
    except:
        st.error("data/meta_lookup.pkl íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None, None, None

    # 2. ë§¤í•‘ ë°ì´í„° (ID ë³€í™˜)
    try:
        with open("data/recbole_vocab.pkl", "rb") as f:
            vocab = pickle.load(f)
        
        token2id = vocab['token2id']
        id2token = vocab['id2token']
        
        # -----------------------------------------------------------
        # [í•µì‹¬ ìˆ˜ì •] id2tokenì´ Numpy ë°°ì—´ì´ë¼ë©´ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜!
        # -----------------------------------------------------------
        if not isinstance(id2token, dict):
            # ë°°ì—´ì˜ ì¸ë±ìŠ¤(0, 1, 2...)ê°€ ê³§ IDì…ë‹ˆë‹¤.
            # enumerateë¥¼ ì¨ì„œ {0: 'pad', 1: '8685', ...} í˜•íƒœë¡œ ë°”ê¿‰ë‹ˆë‹¤.
            id2token = {i: str(token) for i, token in enumerate(id2token)}
            
        # token2idë„ ì•ˆì „í•˜ê²Œ ë¬¸ìì—´ í‚¤ë¡œ ì²˜ë¦¬
        if not isinstance(token2id, dict):
             # RecBole token2idëŠ” ë³´í†µ dictì§€ë§Œ ì•ˆì „ì„ ìœ„í•´ í™•ì¸
             pass 

    except Exception as e:
        st.error(f"ë§¤í•‘ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None, None, None
        
    return all_df, token2id, id2token


@st.cache_data
def load_cycle_data():
    """ì¬êµ¬ë§¤ ì£¼ê¸° ì •ë³´(P10, P25, P50) ë¡œë“œ"""
    try:
        with open("data/item_cycle_lookup.pkl", "rb") as f:
            return pickle.load(f)
    except Exception as e:
        # íŒŒì¼ì´ ì—†ê±°ë‚˜ ì—ëŸ¬ë‚˜ë©´ ë¹ˆ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜ (ì—ëŸ¬ ë°©ì§€)
        return {} 


@st.cache_resource
def load_models():
    # ------------------------------------
    # SASRec ë¡œë“œ
    # ------------------------------------
    sas_path = 'data/SASRec-Nov-27-2025_10-12-11.pth'
    sas_model, sas_n_items = None, 0
    try:
        checkpoint = torch.load(sas_path, map_location=DEVICE, weights_only=False)
        sas_n_items = checkpoint['state_dict']['item_embedding.weight'].shape[0]
        sas_model = SASRec(checkpoint['config'], MockDataset(sas_n_items)).to(DEVICE)
        sas_model.load_state_dict(checkpoint['state_dict'])
        sas_model.eval()
    except Exception as e:
        st.warning(f"SASRec ë¡œë“œ ì‹¤íŒ¨: {e}")

    # ------------------------------------
    # TiSASRec ë¡œë“œ
    # ------------------------------------
    tis_path = 'data/TiSASRec-Nov-28-2025_09-45-58.pth'
    tis_model, tis_n_items = None, 0
    tis_maxlen, tis_timespan = 50, 256
    try:
        checkpoint = torch.load(tis_path, map_location=DEVICE, weights_only=False)
        tis_n_items = checkpoint['state_dict']['item_embedding.weight'].shape[0]
        config = checkpoint['config']
        
        tis_model = TiSASRec(config, MockDataset(tis_n_items)).to(DEVICE)
        tis_model.load_state_dict(checkpoint['state_dict'])
        tis_model.eval()
        
        tis_maxlen = config['MAX_ITEM_LIST_LENGTH']
        tis_timespan = config['time_span']
    except Exception as e:
        st.error(f"TiSASRec ë¡œë“œ ì‹¤íŒ¨: {e}")

    # ë‘ ëª¨ë¸ ì¤‘ ë” ì‘ì€ í¬ê¸°ë¥¼ ì•ˆì „í•œ Max IDë¡œ ì„¤ì • (ì¸ë±ìŠ¤ ì—ëŸ¬ ë°©ì§€)
    safe_n_items = 0
    if sas_n_items > 0 and tis_n_items > 0:
        safe_n_items = min(sas_n_items, tis_n_items)
    elif tis_n_items > 0:
        safe_n_items = tis_n_items
        
    return sas_model, tis_model, tis_maxlen, tis_timespan, safe_n_items



def check_cycle_filtering(days_ago, cycle_info):
    """
    days_ago: êµ¬ë§¤í•œ ì§€ ë©°ì¹  ì§€ë‚¬ëŠ”ì§€
    cycle_info: {'p10': 7, 'p25': 14, ...}
    Return: Trueë©´ í•„í„°ë§(ì‚­ì œ), Falseë©´ ìƒì¡´
    """
    if not cycle_info: 
        # ì •ë³´ê°€ ì—†ìœ¼ë©´ "ê¸°ë³¸ 7ì¼"ì€ ì¬êµ¬ë§¤ ì•ˆ í•œë‹¤ê³  ê°€ì •
        # ì¦‰, ì‚° ì§€ 7ì¼ ë¯¸ë§Œì´ë©´ í•„í„°ë§(True), 7ì¼ ë„˜ì—ˆìœ¼ë©´ í†µê³¼(False)
        return days_ago < 7
    
    p10 = cycle_info.get('p10', 0)
    p25 = cycle_info.get('p25', 0)
    p50 = cycle_info.get('p50', 0)
    
    t = days_ago
    prob = 0.0

    # êµ¬ê°„ë³„ í™•ë¥  ê³„ì‚° (ì„ í˜• ë³´ê°„)
    if t < p10:
        prob = 0.95  # ë§¤ìš° ìœ„í—˜: 95% í™•ë¥ ë¡œ ì œê±°
    elif p10 <= t < p25:
        # P10 ~ P25: 95% -> 30% ë¡œ ê°ì†Œ
        ratio = (t - p10) / (p25 - p10 + 1e-5)
        prob = 0.95 - (ratio * (0.95 - 0.3))
    elif p25 <= t < p50:
        # P25 ~ P50: 30% -> 0% ë¡œ ê°ì†Œ
        ratio = (t - p25) / (p50 - p25 + 1e-5)
        prob = 0.3 - (ratio * 0.3)
    else:
        prob = 0.0 # ì•ˆì „ êµ¬ê°„: ì œê±° ì•ˆ í•¨
        
    return random.random() < prob



# ------------------------------------------------------------------
# 3. ë©”ì¸ í•¨ìˆ˜
# ------------------------------------------------------------------
def main():
    st.set_page_config(layout="wide", page_title="Recommendation A/B Test")
    st.title("ğŸ›ï¸ ì‡¼í•‘ íŒ¨í„´ ê¸°ë°˜ ì¶”ì²œ A/B í…ŒìŠ¤íŠ¸")

    all_df, token2id, id2token = load_data()
    if all_df is None: return
    
    sas_model, tis_model, tis_maxlen, tis_timespan, safe_n_items = load_models()

    # UI í•„í„°ë§: ëª¨ë¸ì´ ì•„ëŠ” IDë§Œ í‘œì‹œ (ì•ˆì „ì¥ì¹˜)
    # token2idì— ìˆê³ , ê·¸ IDê°€ safe_n_itemsë³´ë‹¤ ì‘ì€ ê²ƒë§Œ ìœ íš¨í•¨
    valid_tokens = [t for t, i in token2id.items() if i < safe_n_items]
    valid_mask = all_df['item_id'].astype(str).isin(valid_tokens)
    
    # 20íšŒ ì´ìƒ êµ¬ë§¤ëœ ê²ƒë§Œ UIì— ë…¸ì¶œ
    ui_df = all_df[valid_mask & (all_df['purchase_count'] >= 20)].copy()

    if 'history' not in st.session_state: st.session_state['history'] = []

    # --- ì‚¬ì´ë“œë°” ---
    st.sidebar.header("ğŸ›’ êµ¬ë§¤ ì´ë ¥ ì¶”ê°€")
    
    if ui_df.empty:
        st.error("ì¡°ê±´ì— ë§ëŠ” ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ë§¤í•‘ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    l1_list = sorted(ui_df['L1'].unique())
    l1_sel = st.sidebar.selectbox("ëŒ€ë¶„ë¥˜", l1_list)
    
    l2_list = sorted(ui_df[ui_df['L1']==l1_sel]['L2'].unique())
    l2_sel = st.sidebar.selectbox("ì¤‘ë¶„ë¥˜", l2_list)
    
    final_df = ui_df[(ui_df['L1']==l1_sel) & (ui_df['L2']==l2_sel)]
    final_df = final_df.sort_values(by='purchase_count', ascending=False)
    
    selected_item = st.sidebar.selectbox(
        "ìƒí’ˆ ì„ íƒ", 
        options=final_df.to_dict('records'), 
        format_func=lambda x: f"{x['Item_Name']} ({x['purchase_count']}íšŒ)"
    )
    
    days_ago = st.sidebar.number_input("ë©°ì¹  ì „ êµ¬ë§¤?", 0, 365, 0)
    
    if st.sidebar.button("ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€"):
        st.session_state['history'].append({
            'item_id': str(selected_item['item_id']),
            'name': selected_item['Item_Name'],
            'days_ago': days_ago
        })
        st.session_state['history'].sort(key=lambda x: x['days_ago'], reverse=True)

    if st.sidebar.button("ì´ˆê¸°í™”"):
        st.session_state['history'] = []
        if 'last_results' in st.session_state: del st.session_state['last_results']
        st.rerun()

    # --- ë©”ì¸ í™”ë©´ ---
    st.subheader("ğŸ“‹ í˜„ì¬ êµ¬ë§¤ ì‹œí€€ìŠ¤")
    if st.session_state['history']:
        hist_df = pd.DataFrame(st.session_state['history'])
        hist_df['ì‹œì '] = hist_df['days_ago'].apply(lambda x: "ì˜¤ëŠ˜" if x==0 else f"{x}ì¼ ì „")
        st.dataframe(hist_df[['ì‹œì ', 'name']], use_container_width=True)
        
        # (main í•¨ìˆ˜ ë‚´ë¶€)
        
        # ì£¼ê¸° ë°ì´í„° ë¡œë“œ (ë©”ì¸ í•¨ìˆ˜ ì´ˆì…ì— ë„£ì–´ë‘ëŠ” ê²Œ ì¢‹ìŒ)
        cycle_data = load_cycle_data() 

        # ... (ì•ë¶€ë¶„ ìƒëµ: cycle_data ë¡œë“œ ë“±) ...
    
    # ------------------------------------------------------------------
    # [ìˆ˜ì • 1] ìŠ¬ë¼ì´ë”ë¥¼ ë²„íŠ¼ ë°–ìœ¼ë¡œ êº¼ëƒ…ë‹ˆë‹¤. (í•­ìƒ ì¡°ì ˆ ê°€ëŠ¥í•˜ê²Œ)
    # ------------------------------------------------------------------
    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ›ï¸ íŒŒë¼ë¯¸í„° íŠœë‹")
    alpha = st.sidebar.slider("ì¬êµ¬ë§¤ ê°€ì¤‘ì¹˜ (Alpha)", 0.0, 10.0, 2.0, 0.1)
    
    # ------------------------------------------------------------------
    # [ìˆ˜ì • 2] ë²„íŠ¼ í´ë¦­ ì‹œ 'ëª¨ë¸ ì¶”ë¡ 'ë§Œ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì„¸ì…˜ì— ì €ì¥
    # ------------------------------------------------------------------
    if st.button("ì¶”ì²œ ê²°ê³¼ ìƒì„±/ì—…ë°ì´íŠ¸", type="primary"):
        if len(st.session_state['history']) < 2:
            st.warning("ì•„ì´í…œì„ 2ê°œ ì´ìƒ ë„£ì–´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("AIê°€ íŒ¨í„´ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                # 1. ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±
                hist_ids, hist_days = [], []
                for h in st.session_state['history']:
                    if h['item_id'] in token2id:
                        internal_id = token2id[h['item_id']]
                        if internal_id < safe_n_items:
                            hist_ids.append(internal_id)
                            hist_days.append(h['days_ago'])
                
                if not hist_ids:
                    st.error("ë°ì´í„° ë²”ìœ„ ì˜¤ë¥˜")
                    st.stop()
                    
                seq_ids = hist_ids[-tis_maxlen:]
                pad_len = tis_maxlen - len(seq_ids)
                input_ids = [0] * pad_len + seq_ids
                
                item_seq = torch.LongTensor([input_ids]).to(DEVICE)
                item_len = torch.LongTensor([tis_maxlen]).to(DEVICE)

                # 2. SASRec ëª¨ë¸ ì¶”ë¡  (ì—¬ê¸°ê°€ ë¬´ê±°ìš´ ì‘ì—…)
                if sas_model:
                    inter_sas = Interaction({'item_id_list': item_seq, 'item_length': item_len})
                    # Raw Logits(ì ìˆ˜)ë§Œ ê³„ì‚°í•´ì„œ ì„¸ì…˜ì— ì €ì¥
                    raw_scores = sas_model.full_sort_predict(inter_sas).detach().cpu().numpy()[0]
                    
                    st.session_state['raw_scores'] = raw_scores
                    st.session_state['has_run'] = True # ì‹¤í–‰ ì™„ë£Œ í”Œë˜ê·¸
    
    # ------------------------------------------------------------------
    # [ìˆ˜ì • 3] ì„¸ì…˜ì— ê²°ê³¼ê°€ ìˆë‹¤ë©´, ìŠ¬ë¼ì´ë” ê°’(alpha)ì„ ë°˜ì˜í•´ ì¦‰ì‹œ ë Œë”ë§
    # ------------------------------------------------------------------
    # ------------------------------------------------------------------
    # ------------------------------------------------------------------
    # [ìˆ˜ì •] ê²°ê³¼ í™”ë©´ ì¶œë ¥ ë° ë¸”ë¼ì¸ë“œ í…ŒìŠ¤íŠ¸ ë¡œì§ (ë¡œê·¸ ê°€ì¤‘ì¹˜ ì ìš©)
    # ------------------------------------------------------------------
    if st.session_state.get('has_run', False):
        raw_scores = st.session_state['raw_scores']
        
        # ===============================================================
        # 1. [ê³„ì‚° ë‹¨ê³„] Logic A (ë¡œê·¸ ê°€ì¤‘ì¹˜) & B ì ìˆ˜ í™•ì •
        # ===============================================================
        
        # --- Logic A: History Boost (ë¡œê·¸ ë°©ì‹ ì ìš©) ---
        scores_A = raw_scores.copy()
        
        # 1. ì•„ì´í…œë³„ êµ¬ë§¤ íšŸìˆ˜ ì¹´ìš´íŒ…
        item_counts = {}
        for h in st.session_state['history']:
            raw_id = h['item_id']
            item_counts[raw_id] = item_counts.get(raw_id, 0) + 1
            
        # 2. ë¡œê·¸ ê°€ì¤‘ì¹˜ ê³„ì‚° (alpha ì ìš©)
        for raw_id, count in item_counts.items():
            if raw_id in token2id:
                idx = token2id[raw_id]
                if idx < len(scores_A):
                    # ln(1 + íšŸìˆ˜) * alpha
                    boost_score = alpha * np.log1p(count)
                    scores_A[idx] += boost_score

        # 3. Top 10 ì„ ì • (A í™”ë©´ìš©)
        topk_A_ids = np.argsort(scores_A)[::-1][:10]

        # --- Logic B: Cycle Filtering ---
        scores_B = scores_A.copy() # A ì ìˆ˜ì—ì„œ ì‹œì‘
        filtered_debug_info = {}   # ë””ë²„ê¹…ìš©: ëˆ„ê°€ ì™œ í•„í„°ë§ëëŠ”ì§€ ì €ì¥
        
        for h in st.session_state['history']:
            raw_id = h['item_id']
            days = h['days_ago']
            if raw_id in token2id:
                idx = token2id[raw_id]
                if idx < len(scores_B):
                    c_info = cycle_data.get(raw_id, {})
                    
                    # [í•µì‹¬] í•„í„°ë§ íŒì • (ë”± í•œ ë²ˆë§Œ ìˆ˜í–‰)
                    is_filtered = check_cycle_filtering(days, c_info)
                    
                    if is_filtered:
                        scores_B[idx] = -np.inf # ì ìˆ˜ ì‚­ì œ
                        # ì´ìœ  ê¸°ë¡
                        if not c_info:
                            filtered_debug_info[idx] = f"{days}ì¼ ì „ êµ¬ë§¤ (ë°ì´í„° ì—†ìŒ: 7ì¼ ë£°)"
                        else:
                            filtered_debug_info[idx] = f"{days}ì¼ ì „ êµ¬ë§¤ (ì¬êµ¬ë§¤ ì£¼ê¸° ë¯¸ë„ë˜)"
        
        topk_B_ids = np.argsort(scores_B)[::-1][:10]

        # ===============================================================
        # 2. [ë¸”ë¼ì¸ë“œ ì„¤ì •] A/B ëœë¤ ì„ê¸° (ìµœì´ˆ 1íšŒë§Œ ìˆ˜í–‰)
        # ===============================================================
        
        # ì„¸ì…˜ì— ë§¤í•‘ ì •ë³´ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„± (ìƒˆë¡œìš´ ì¶”ì²œì´ ìƒì„±ë  ë•Œë§ˆë‹¤ ê°±ì‹  í•„ìš”)
        # *ì£¼ì˜: ì™¸ë¶€ ë²„íŠ¼ í´ë¦­ ì‹œ st.session_state['ab_mapping']ì„ del í•´ì£¼ëŠ” ë¡œì§ì´ ìˆìœ¼ë©´ ì¢‹ìŠµë‹ˆë‹¤.
        # ì—¬ê¸°ì„œëŠ” ì•ˆì „í•˜ê²Œ ì—†ìœ¼ë©´ ë§Œë“œëŠ” ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        if 'ab_mapping' not in st.session_state:
            st.session_state['ab_mapping'] = random.choice(['A_is_1', 'B_is_1'])
            st.session_state['experiment_submitted'] = False

        mapping = st.session_state['ab_mapping']
        
        # ë§¤í•‘ì— ë”°ë¼ ì˜µì…˜ í• ë‹¹
        if mapping == 'A_is_1':
            opt1_ids, opt1_name = topk_A_ids, "Logic A (ë¶€ìŠ¤íŒ… Only)"
            opt2_ids, opt2_name = topk_B_ids, "Logic B (ë¶€ìŠ¤íŒ… + í•„í„°ë§)"
        else:
            opt1_ids, opt1_name = topk_B_ids, "Logic B (ë¶€ìŠ¤íŒ… + í•„í„°ë§)"
            opt2_ids, opt2_name = topk_A_ids, "Logic A (ë¶€ìŠ¤íŒ… Only)"

        # Helper: ë‹¨ìˆœ ì •ë³´ ì¡°íšŒ (ë¸”ë¼ì¸ë“œìš©)
        def get_simple_info(idx):
            name, cat = "Unknown", ""
            if idx in id2token:
                raw_id = id2token[idx]
                row = all_df[all_df['item_id'].astype(str) == raw_id]
                if not row.empty:
                    name = row.iloc[0]['Item_Name']
                    cat = row.iloc[0]['L2']
            return f"[{cat}] {name}"

        # ===============================================================
        # 3. [í™”ë©´ ì¶œë ¥] 1ë‹¨ê³„: ë¸”ë¼ì¸ë“œ í…ŒìŠ¤íŠ¸ (ì œì¶œ ì „)
        # ===============================================================
        st.divider()
        st.subheader("âš–ï¸ ë¸”ë¼ì¸ë“œ í…ŒìŠ¤íŠ¸: ë” ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì¶”ì²œì€?")
        
        bc1, bc2 = st.columns(2)
        with bc1:
            st.markdown("### ğŸ…°ï¸ Option 1")
            for rank, idx in enumerate(opt1_ids):
                if idx == 0: continue
                st.write(f"{rank+1}. {get_simple_info(idx)}")

        with bc2:
            st.markdown("### ğŸ…±ï¸ Option 2")
            for rank, idx in enumerate(opt2_ids):
                if idx == 0: continue
                st.write(f"{rank+1}. {get_simple_info(idx)}")

        # ===============================================================
        # 4. [ì…ë ¥ í¼] ì„ íƒ ë° ì‚¬ìœ  ì…ë ¥
        # ===============================================================
        st.markdown("---")
        with st.form("ab_test_form"):
            st.write("ğŸ“ **í‰ê°€ ì…ë ¥**")
            st.info("ë‘ ì˜µì…˜ ì¤‘ ë” êµ¬ë§¤ ì˜ì‚¬ê°€ ë†’ì€ ì¶”ì²œ ëª©ë¡ì„ ì„ íƒí•˜ê³  ì´ìœ ë¥¼ ì ì–´ì£¼ì„¸ìš”.")
            choice = st.radio("ë” ë§ˆìŒì— ë“œëŠ” ì¶”ì²œ ê²°ê³¼ëŠ”?", ["Option 1", "Option 2"], horizontal=True)
            reason = st.text_area("ì„ íƒí•œ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”? (ì˜ˆ: ì¬êµ¬ë§¤ ìƒí’ˆì´ ì ì ˆí•´ì„œ / ë¶ˆí•„ìš”í•œ ì¶”ì²œì´ ì—†ì–´ì„œ ë“±)")
            
            submitted = st.form_submit_button("ì œì¶œ ë° ê²°ê³¼ í™•ì¸", type="primary")
            
            if submitted:
                st.session_state['experiment_submitted'] = True
                st.session_state['user_choice'] = choice
                st.session_state['user_reason'] = reason

        # ===============================================================
        # 5. [ê²°ê³¼ ê³µê°œ] ì œì¶œ í›„ ì •ë‹µ ë° ìƒì„¸ ë¶„ì„ í‘œì‹œ
        # ===============================================================
        if st.session_state.get('experiment_submitted', False):
            st.divider()
            st.header("ğŸ”“ ê²°ê³¼ ê³µê°œ ë° ë¶„ì„")
            
            # 1. ì‚¬ìš©ì ì„ íƒ ê²°ê³¼ ìš”ì•½
            user_pick = st.session_state['user_choice']
            real_logic = opt1_name if user_pick == "Option 1" else opt2_name
            
            st.success(f"âœ… ë‹¹ì‹ ì˜ ì„ íƒ: **{user_pick}**")
            st.info(f"ğŸ’¡ ì‹¤ì œ ë¡œì§: **{real_logic}**")
            st.write(f"ğŸ—£ï¸ ì‘ì„±í•œ ì´ìœ : {st.session_state['user_reason']}")
            
            # (ë°ì´í„° ìˆ˜ì§‘ ë¡œê·¸ - ë‚˜ì¤‘ì— DB ì €ì¥ìš©)
            log_data = {
                "alpha": alpha,
                "option1": opt1_name,
                "option2": opt2_name,
                "choice": user_pick,
                "reason": st.session_state['user_reason']
            }

            # (ë°ì´í„° ìˆ˜ì§‘ ë¡œê·¸ - ë”•ì…”ë„ˆë¦¬ ìƒì„± ë¶€ë¶„)
            log_data = {
                "timestamp": pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'), # ì‹œê°„ ì¶”ê°€
                "user_choice": user_pick,
                "logic_A": opt1_name, # ì–´ë–¤ ë¡œì§ì´ Aì˜€ëŠ”ì§€
                "logic_B": opt2_name, # ì–´ë–¤ ë¡œì§ì´ Bì˜€ëŠ”ì§€
                "alpha": alpha,
                "reason": st.session_state['user_reason'],
                "history_len": len(st.session_state['history']),
                "history_items": str([h['name'] for h in st.session_state['history']]) # ë³´ê¸° í¸í•˜ê²Œ ì´ë¦„ë§Œ ì €ì¥
            }
            
            # (ë¡œê·¸ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ìƒì„± í›„...)
            new_df = pd.DataFrame([log_data])

            # ---------------------------------------------------------
            # [ìˆ˜ì •] Google Sheetsì— ì €ì¥í•˜ê¸° (í´ë¼ìš°ë“œìš©)
            # ---------------------------------------------------------
            try:
                # 1. ì—°ê²° ê°ì²´ ìƒì„±
                conn = st.connection("gsheets", type=GSheetsConnection)
                
                # 2. ê¸°ì¡´ ë°ì´í„° ì½ê¸° (ì—†ìœ¼ë©´ ë¹ˆ DF)
                try:
                    existing_data = conn.read(worksheet="Sheet1", usecols=list(range(len(log_data.keys()))), ttl=5)
                    updated_data = pd.concat([existing_data, new_df], ignore_index=True)
                except:
                    updated_data = new_df

                # 3. ë°ì´í„° ì—…ë°ì´íŠ¸
                conn.update(worksheet="Sheet1", data=updated_data)
                
                st.success("â˜ï¸ ë°ì´í„°ê°€ êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì— ì•ˆì „í•˜ê²Œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                
            except Exception as e:
                st.error(f"ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
                # í˜¹ì‹œ ëª¨ë¥´ë‹ˆ ë°±ì—…ìš©ìœ¼ë¡œ CSV ì €ì¥ (ì„ì‹œ)
                new_df.to_csv("backup_logs.csv", mode='a', header=False, index=False)

            # 2. ìƒì„¸ ì‹œê°í™”
            st.subheader("ğŸ“Š ìƒì„¸ ë¶„ì„ (Why?)")
            
            # Helper: ìƒì„¸ ì •ë³´ ì¡°íšŒ
            def get_item_info_detail(idx):
                name, cat, raw_id = "Unknown", "", None
                if idx in id2token:
                    raw_id = id2token[idx]
                    row = all_df[all_df['item_id'].astype(str) == raw_id]
                    if not row.empty:
                        name = row.iloc[0]['Item_Name']
                        cat = row.iloc[0]['L2']
                return raw_id, cat, name

            rc1, rc2 = st.columns(2)
            
            # --- Logic A ê²°ê³¼ (ì™¼ìª½ ê³ ì •) ---
            with rc1:
                st.markdown(f"### Logic A: ë‹¨ìˆœ ë¶€ìŠ¤íŒ…")
                st.caption("(í•„í„°ë§ ì˜ˆì • ìƒí’ˆì€ :orange[ì£¼í™©ìƒ‰] ê²½ê³ )")
                
                for rank, idx in enumerate(topk_A_ids):
                    if idx == 0: continue
                    raw_id, cat, name = get_item_info_detail(idx)
                    score_val = scores_A[idx]
                    
                    # Logic Bì—ì„œ í•„í„°ë§ë˜ì—ˆëŠ”ì§€ í™•ì¸ (ì ìˆ˜ê°€ -infì¸ì§€ ì²´í¬)
                    is_filtered_in_B = (scores_B[idx] == -np.inf)
                    
                    if is_filtered_in_B:
                        reason_txt = filtered_debug_info.get(idx, "í•„í„°ë§ë¨")
                        st.markdown(f"**{rank+1}. :orange[[{cat}] {name}]** âš ï¸")
                        st.caption(f":orange[Score: {score_val:.2f} (í•„í„°ë§ ì˜ˆì •: {reason_txt})]")
                    else:
                        st.markdown(f"**{rank+1}. [{cat}] {name}**")
                        st.caption(f"Score: {score_val:.2f}")

            # --- Logic B ê²°ê³¼ (ì˜¤ë¥¸ìª½ ê³ ì •) ---
            with rc2:
                st.markdown(f"### Logic B: ìŠ¤ë§ˆíŠ¸ í•„í„°ë§")
                st.caption("(ìƒˆë¡œ ì§„ì…í•œ ìƒí’ˆì€ :green[ì´ˆë¡ìƒ‰] ê°•ì¡°)")
                
                for rank, idx in enumerate(topk_B_ids):
                    if idx == 0: continue
                    raw_id, cat, name = get_item_info_detail(idx)
                    score_val = scores_B[idx]
                    
                    is_new_entry = idx not in topk_A_ids
                    
                    if is_new_entry:
                        st.markdown(f"**{rank+1}. :green[[{cat}] {name}]** (New! âœ¨)")
                        st.caption(f":green[Score: {score_val:.2f} (ìˆœìœ„ ìƒìŠ¹ ì§„ì…)]")
                    else:
                        st.markdown(f"**{rank+1}. [{cat}] {name}**")
                        st.caption(f"Score: {score_val:.2f}")

if __name__ == "__main__":
    main()