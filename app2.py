import streamlit as st
import pandas as pd
import torch
import random
import os
import sys
import pickle
import numpy as np
import re  # ì •ê·œí‘œí˜„ì‹ ì‚¬ìš© (ìˆ«ì ì¶”ì¶œ)

# ------------------------------------------------------------------
# 1. [í•„ìˆ˜] ëª¨ë“ˆ ê²½ë¡œ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ì§œ ë“±ë¡ (ì—ëŸ¬ ë°©ì§€)
# ------------------------------------------------------------------
import tisasrec_local
sys.modules['TiSASRec'] = tisasrec_local

from types import ModuleType
def mock_lib(name):
    if name not in sys.modules: sys.modules[name] = ModuleType(name)
    return sys.modules[name]

for lib in ['kmeans_pytorch', 'lightgbm', 'xgboost', 'ray', 'hyperopt', 'colorama']:
    mock_lib(lib)
    sys.modules[f"{lib}.sklearn"] = mock_lib(f"{lib}.sklearn")

if 'kmeans_pytorch' in sys.modules:
    sys.modules['kmeans_pytorch'].kmeans = lambda *args, **kwargs: (None, None)

# RecBole íŒ¨ì¹˜
import recbole
if not hasattr(recbole, 'utils'):
    recbole.utils = ModuleType('recbole.utils')
    sys.modules['recbole.utils'] = recbole.utils

if not hasattr(recbole.utils, 'enum_type'):
    m_enum = ModuleType('recbole.utils.enum_type')
    sys.modules['recbole.utils.enum_type'] = m_enum
    recbole.utils.enum_type = m_enum
    class Dummy:
        def __init__(self, *args, **kwargs): pass
    for cls in ['ModelType', 'DataLoaderType', 'KGDataLoaderState', 'EvaluatorType', 'InputType', 'FeatureType']:
        setattr(m_enum, cls, Dummy)

# ------------------------------------------------------------------
# 2. ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ
# ------------------------------------------------------------------
from recbole.model.sequential_recommender.sasrec import SASRec
from tisasrec_local import TiSASRec
from recbole.data.interaction import Interaction
from utils import get_tisasrec_input

DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class MockDataset:
    def __init__(self, n_items):
        self.n_items = n_items
    def num(self, field):
        return self.n_items

@st.cache_data
def load_data():
    # 1. ë©”íƒ€ ë°ì´í„°
    try:
        all_df = pd.read_pickle('data/meta_lookup.pkl')
    except:
        st.error("meta_lookup.pkl ì—†ìŒ")
        return None, None, None

    # 2. ë§¤í•‘ ë°ì´í„°
    try:
        with open("data/recbole_vocab.pkl", "rb") as f:
            vocab = pickle.load(f)
        token2id = vocab['token2id']
        id2token = vocab['id2token']
        
        # ë°°ì—´ -> ë”•ì…”ë„ˆë¦¬ ë³€í™˜ (ì•ˆì „ì¥ì¹˜)
        if not isinstance(id2token, dict):
            id2token = {i: str(token) for i, token in enumerate(id2token)}
            
    except:
        st.error("recbole_vocab.pkl ì—†ìŒ. get_true_vocab.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return None, None, None
        
    return all_df, token2id, id2token

@st.cache_resource
def load_models():
    # SASRec
    sas_path = 'data/SASRec-Nov-27-2025_10-12-11.pth'
    sas_model, sas_items = None, 0
    try:
        ckpt = torch.load(sas_path, map_location=DEVICE, weights_only=False)
        sas_items = ckpt['state_dict']['item_embedding.weight'].shape[0]
        sas_model = SASRec(ckpt['config'], MockDataset(sas_items)).to(DEVICE)
        sas_model.load_state_dict(ckpt['state_dict'])
        sas_model.eval()
    except Exception as e:
        st.warning(f"SASRec ë¡œë“œ ì‹¤íŒ¨: {e}")

    # TiSASRec
    tis_path = 'data/TiSASRec-Nov-28-2025_09-45-58.pth'
    tis_model, tis_items = None, 0
    tis_maxlen, tis_timespan = 50, 256
    try:
        ckpt = torch.load(tis_path, map_location=DEVICE, weights_only=False)
        tis_items = ckpt['state_dict']['item_embedding.weight'].shape[0]
        conf = ckpt['config']
        tis_model = TiSASRec(conf, MockDataset(tis_items)).to(DEVICE)
        tis_model.load_state_dict(ckpt['state_dict'])
        tis_model.eval()
        tis_maxlen = conf['MAX_ITEM_LIST_LENGTH']
        tis_timespan = conf['time_span']
    except Exception as e:
        st.error(f"TiSASRec ë¡œë“œ ì‹¤íŒ¨: {e}")

    # ì•ˆì „í•œ ì•„ì´í…œ ë²”ìœ„ ì„¤ì •
    safe_n = min(sas_items, tis_items) if sas_items and tis_items else (tis_items or sas_items)
        
    return sas_model, tis_model, tis_maxlen, tis_timespan, safe_n

# ------------------------------------------------------------------
# 3. [ì¶”ê°€] í˜ë¥´ì†Œë‚˜ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
# ------------------------------------------------------------------
def load_persona_history(all_df):
    persona_path = 'data/ì—¬ì_ëŒ€í•™ìƒ_ìƒˆë‚´ê¸°.csv' # íŒŒì¼ ê²½ë¡œ (data í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”)
    
    if not os.path.exists(persona_path):
        st.error(f"í˜ë¥´ì†Œë‚˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {persona_path}")
        return []

    try:
        df = pd.read_csv(persona_path)
        history = []
        
        for _, row in df.iterrows():
            # 1. ì‹œì  ë³€í™˜: "30ì¼ ì „" -> 30 (ìˆ«ìë§Œ ì¶”ì¶œ)
            days_str = str(row['ì‹œì '])
            days = int(re.sub(r'[^0-9]', '', days_str))
            
            # 2. ì´ë¦„ìœ¼ë¡œ ì•„ì´í…œ ID ì°¾ê¸°
            item_name = row['ìƒí’ˆ ì„ íƒ'] # CSV ì»¬ëŸ¼ëª… í™•ì¸ í•„ìš”
            
            # meta_dfì—ì„œ ì´ë¦„ì´ ì¼ì¹˜í•˜ëŠ” í–‰ ì°¾ê¸°
            matched_row = all_df[all_df['Item_Name'] == item_name]
            
            if not matched_row.empty:
                # ì²« ë²ˆì§¸ ë§¤ì¹­ë˜ëŠ” ì•„ì´í…œì˜ ID ì‚¬ìš©
                item_id = str(matched_row.iloc[0]['item_id'])
                
                history.append({
                    'item_id': item_id,
                    'name': item_name,
                    'days_ago': days
                })
            else:
                # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ë¡œê·¸ (ë””ë²„ê¹…ìš©)
                print(f"ë§¤í•‘ ì‹¤íŒ¨: {item_name}")
                
        return history
        
    except Exception as e:
        st.error(f"í˜ë¥´ì†Œë‚˜ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        return []

# ------------------------------------------------------------------
# 4. ë©”ì¸ ë¡œì§
# ------------------------------------------------------------------
def main():
    st.set_page_config(layout="wide", page_title="Recommendation A/B Test")
    st.title("ğŸ›ï¸ ì‡¼í•‘ íŒ¨í„´ ê¸°ë°˜ ì¶”ì²œ A/B í…ŒìŠ¤íŠ¸")

    all_df, token2id, id2token = load_data()
    if all_df is None: return
    
    sas_model, tis_model, tis_maxlen, tis_timespan, safe_n = load_models()

    # UIìš© ë°ì´í„° í•„í„°ë§
    valid_tokens = [t for t, i in token2id.items() if i < safe_n]
    ui_df = all_df[all_df['item_id'].astype(str).isin(valid_tokens) & (all_df['purchase_count'] >= 10)].copy()

    if 'history' not in st.session_state: st.session_state['history'] = []

    # --- ì‚¬ì´ë“œë°” ---
    st.sidebar.header("ğŸ›’ êµ¬ë§¤ ì´ë ¥ êµ¬ì„±")
    
    # [ì¶”ê°€ë¨] í˜ë¥´ì†Œë‚˜ ë¡œë“œ ë²„íŠ¼
    st.sidebar.subheader("1. ê¸°ë³¸ ì‹œí€€ìŠ¤ ì„¤ì •")
    if st.sidebar.button("ğŸ‘©â€ğŸ“ ì—¬ëŒ€ìƒ ìƒˆë‚´ê¸° ëª¨ë“œ ì ìš©"):
        persona_history = load_persona_history(all_df)
        if persona_history:
            st.session_state['history'] = persona_history
            # ë‚ ì§œìˆœ ì •ë ¬ (ê³¼ê±° -> í˜„ì¬)
            st.session_state['history'].sort(key=lambda x: x['days_ago'], reverse=True)
            st.success("ì—¬ëŒ€ìƒ í˜ë¥´ì†Œë‚˜ ë¡œë“œ ì™„ë£Œ!")
            st.rerun()

    st.sidebar.divider()
    
    st.sidebar.subheader("2. ì§ì ‘ ì¶”ê°€í•˜ê¸°")
    if ui_df.empty:
        st.error("ë°ì´í„° ì—†ìŒ")
        return

    l1 = st.sidebar.selectbox("ëŒ€ë¶„ë¥˜", sorted(ui_df['L1'].unique()))
    l2 = st.sidebar.selectbox("ì¤‘ë¶„ë¥˜", sorted(ui_df[ui_df['L1']==l1]['L2'].unique()))
    items = ui_df[(ui_df['L1']==l1) & (ui_df['L2']==l2)].sort_values(by='purchase_count', ascending=False)
    
    sel_item = st.sidebar.selectbox("ìƒí’ˆ ì„ íƒ", options=items.to_dict('records'), 
                                  format_func=lambda x: f"{x['Item_Name']} ({x['purchase_count']}íšŒ)")
    days = st.sidebar.number_input("ë©°ì¹  ì „?", 0, 365, 0)
    
    if st.sidebar.button("ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€"):
        st.session_state['history'].append({
            'item_id': str(sel_item['item_id']), 
            'name': sel_item['Item_Name'], 
            'days_ago': days
        })
        st.session_state['history'].sort(key=lambda x: x['days_ago'], reverse=True)

    if st.sidebar.button("ì´ˆê¸°í™” (ì „ì²´ ì‚­ì œ)"):
        st.session_state['history'] = []
        st.session_state.pop('last_results', None)
        st.rerun()

    # --- Main ---
    st.subheader("ğŸ“‹ í˜„ì¬ ì‹œí€€ìŠ¤ (TimeLine)")
    if st.session_state['history']:
        hist_df = pd.DataFrame(st.session_state['history'])
        hist_df['ì‹œì '] = hist_df['days_ago'].apply(lambda x: "ì˜¤ëŠ˜" if x==0 else f"{x}ì¼ ì „")
        st.dataframe(hist_df[['ì‹œì ', 'name']], width=700)
        
        if st.button("ì¶”ì²œ ê²°ê³¼ ë³´ê¸° (Inference)", type="primary"):
            if len(st.session_state['history']) < 2:
                st.warning("2ê°œ ì´ìƒ ì…ë ¥í•˜ì„¸ìš”.")
            else:
                with st.spinner("AI ë¶„ì„ ì¤‘..."):
                    # 1. ì…ë ¥ ë³€í™˜ (ë§¤í•‘ì€ í•˜ë‚˜ë§Œ ì”ë‹ˆë‹¤!)
                    ids, days_list = [], []
                    for h in st.session_state['history']:
                        if h['item_id'] in token2id:
                            internal = token2id[h['item_id']]
                            if internal < safe_n:
                                ids.append(internal)
                                days_list.append(h['days_ago'])
                    
                    if not ids: st.stop()

                    # 2. í…ì„œ ì¤€ë¹„
                    seq = ids[-tis_maxlen:]
                    d_seq = days_list[-tis_maxlen:]
                    pad = tis_maxlen - len(seq)
                    input_ts = torch.LongTensor([[0]*pad + seq]).to(DEVICE)
                    
                    # [ì¤‘ìš”] ê¸¸ì´ëŠ” í•­ìƒ maxlenìœ¼ë¡œ ê³ ì • (ëë°©ì„ ë³´ê²Œ í•¨)
                    len_ts = torch.LongTensor([tis_maxlen]).to(DEVICE)
                    
                    # 3. ì¶”ë¡ 
                    res = []
                    
                    # [A] SASRec
                    if sas_model:
                        scores = sas_model.full_sort_predict(Interaction({'item_id_list': input_ts, 'item_length': len_ts}))
                        topk = torch.topk(scores, 10).indices.cpu().numpy()[0]
                        res.append({'name': 'SASRec', 'ids': topk})
                        
                    # [B] TiSASRec
                    if tis_model:
                        t_seq, t_mat = get_tisasrec_input(d_seq, tis_maxlen, tis_timespan)
                        inter = Interaction({
                            'item_id_list': input_ts, 'item_length': len_ts,
                            'timestamp_list': t_seq.to(DEVICE), 'time_matrix': t_mat.to(DEVICE)
                        })
                        scores = tis_model.full_sort_predict(inter)
                        topk = torch.topk(scores, 10).indices.cpu().numpy()[0]
                        res.append({'name': 'TiSASRec', 'ids': topk})

                    # 4. ê²°ê³¼ ë³€í™˜
                    random.shuffle(res)
                    
                    def ids_to_text(ids):
                        lines = []
                        for i in ids:
                            if i==0: continue
                            if i in id2token:
                                raw = id2token[i]
                                row = all_df[all_df['item_id'].astype(str) == raw]
                                if not row.empty:
                                    d = row.iloc[0]
                                    lines.append(f"**[{d['L1']} > {d['L2']}]**\n{d['Item_Name']}")
                                else:
                                    lines.append(f"Unknown ({raw})")
                            else:
                                lines.append(f"Unknown ID {i}")
                        return lines

                    st.session_state['last_results'] = [
                        {'name': r['name'], 'texts': ids_to_text(r['ids'])} for r in res
                    ]

    if 'last_results' in st.session_state:
        st.divider()
        c1, c2 = st.columns(2)
        r = st.session_state['last_results']
        
        with c1:
            st.info("### ê²°ê³¼ A")
            for i, t in enumerate(r[0]['texts']): st.markdown(f"{i+1}. {t}")
            if st.button("ğŸ‘ A ìŠ¹ë¦¬"): st.success(f"ìŠ¹ì: {r[0]['name']}")
            
        with c2:
            st.info("### ê²°ê³¼ B")
            for i, t in enumerate(r[1]['texts']): st.markdown(f"{i+1}. {t}")
            if st.button("ğŸ‘ B ìŠ¹ë¦¬"): st.success(f"ìŠ¹ì: {r[1]['name']}")

if __name__ == "__main__":
    main()