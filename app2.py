import streamlit as st
import pandas as pd
import torch
import random
import os
import sys
import pickle
import numpy as np
import re
import glob

# ------------------------------------------------------------------
# 1. [í•„ìˆ˜] ëª¨ë“ˆ ê²½ë¡œ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ì§œ ë“±ë¡ (ê¸°ì¡´ ìœ ì§€)
# ------------------------------------------------------------------
import tisasrec_local
sys.modules['TiSASRec'] = tisasrec_local

from types import ModuleType
def mock_lib(name):
    if name not in sys.modules: sys.modules[name] = ModuleType(name)
    return sys.modules[name]

for lib in ['kmeans_pytorch', 'lightgbm', 'xgboost', 'ray', 'hyperopt', 'colorama']:
    mock_lib(lib)
    sys.modules[f"{lib}.sklearn"] = mock_lib(f"{lib}.sklearn")

if 'kmeans_pytorch' in sys.modules:
    sys.modules['kmeans_pytorch'].kmeans = lambda *args, **kwargs: (None, None)

import recbole
if not hasattr(recbole, 'utils'):
    recbole.utils = ModuleType('recbole.utils')
    sys.modules['recbole.utils'] = recbole.utils

if not hasattr(recbole.utils, 'enum_type'):
    m_enum = ModuleType('recbole.utils.enum_type')
    sys.modules['recbole.utils.enum_type'] = m_enum
    recbole.utils.enum_type = m_enum
    class Dummy:
        def __init__(self, *args, **kwargs): pass
    for cls in ['ModelType', 'DataLoaderType', 'KGDataLoaderState', 'EvaluatorType', 'InputType', 'FeatureType']:
        setattr(m_enum, cls, Dummy)

# ------------------------------------------------------------------
# 2. ë°ì´í„° ë° ëª¨ë¸ ë¡œë“œ
# ------------------------------------------------------------------
from recbole.model.sequential_recommender.sasrec import SASRec
from tisasrec_local import TiSASRec
from recbole.data.interaction import Interaction
from utils import get_tisasrec_input

DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class MockDataset:
    def __init__(self, n_items):
        self.n_items = n_items
    def num(self, field):
        return self.n_items

@st.cache_data
def load_data():
    try:
        all_df = pd.read_pickle('data/meta_lookup.pkl')
    except:
        st.error("data/meta_lookup.pkl íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None, None, None

    try:
        with open("data/recbole_vocab.pkl", "rb") as f:
            vocab_tis = pickle.load(f)
        if not isinstance(vocab_tis['id2token'], dict):
            vocab_tis['id2token'] = {i: str(t) for i, t in enumerate(vocab_tis['id2token'])}
    except:
        st.error("recbole_vocab.pkl (TiSASRecìš©) ì—†ìŒ")
        return None, None, None, None, None

    try:
        with open("data/sasrec_vocab.pkl", "rb") as f:
            vocab_sas = pickle.load(f)
        if not isinstance(vocab_sas['id2token'], dict):
            vocab_sas['id2token'] = {i: str(t) for i, t in enumerate(vocab_sas['id2token'])}
    except:
        st.error("sasrec_vocab.pkl (SASRecìš©) ì—†ìŒ")
        return None, None, None, None, None
        
    return all_df, vocab_tis, vocab_sas

@st.cache_resource
def load_models():
    # SASRec
    sas_path = 'data/SASRec-Nov-27-2025_10-12-11.pth'
    sas_model, sas_items = None, 0
    try:
        ckpt = torch.load(sas_path, map_location=DEVICE, weights_only=False)
        sas_items = ckpt['state_dict']['item_embedding.weight'].shape[0]
        sas_model = SASRec(ckpt['config'], MockDataset(sas_items)).to(DEVICE)
        sas_model.load_state_dict(ckpt['state_dict'])
        sas_model.eval()
    except Exception as e:
        st.warning(f"SASRec ë¡œë“œ ì‹¤íŒ¨: {e}")

    # TiSASRec
    tis_path = 'data/TiSASRec-Nov-28-2025_09-45-58.pth'
    tis_model, tis_items = None, 0
    tis_maxlen, tis_timespan = 50, 256
    try:
        ckpt = torch.load(tis_path, map_location=DEVICE, weights_only=False)
        tis_items = ckpt['state_dict']['item_embedding.weight'].shape[0]
        conf = ckpt['config']
        tis_model = TiSASRec(conf, MockDataset(tis_items)).to(DEVICE)
        tis_model.load_state_dict(ckpt['state_dict'])
        tis_model.eval()
        tis_maxlen = conf['MAX_ITEM_LIST_LENGTH']
        tis_timespan = conf['time_span']
    except Exception as e:
        st.error(f"TiSASRec ë¡œë“œ ì‹¤íŒ¨: {e}")

    safe_n = min(sas_items, tis_items) if sas_items and tis_items else (tis_items or sas_items)
        
    return sas_model, tis_model, tis_maxlen, tis_timespan, safe_n

# ------------------------------------------------------------------
# 3. [ê¸°ëŠ¥ ì—…ê·¸ë ˆì´ë“œ] í˜ë¥´ì†Œë‚˜ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ (í´ë” ê²½ë¡œ ìˆ˜ì • ë°˜ì˜)
# ------------------------------------------------------------------
def load_persona_history(all_df, filename):
    # data/personas í´ë” ì•ˆì—ì„œ íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤.
    persona_path = os.path.join('data', 'personas', filename)
    
    if not os.path.exists(persona_path):
        st.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {persona_path}")
        return []

    try:
        # í•œê¸€ ì¸ì½”ë”© í˜¸í™˜ì„± ì²˜ë¦¬
        try:
            df = pd.read_csv(persona_path, encoding='utf-8')
        except UnicodeDecodeError:
            df = pd.read_csv(persona_path, encoding='cp949')

        history = []
        for _, row in df.iterrows():
            # 1. ì‹œì  ë³€í™˜: "30ì¼ ì „" -> 30 (ìˆ«ìë§Œ ì¶”ì¶œ)
            days_str = str(row.get('ì‹œì ', '0'))
            days_match = re.search(r'\d+', days_str)
            days = int(days_match.group()) if days_match else 0
            
            # 2. ì•„ì´í…œ ì´ë¦„ í™•ì¸ (csv ì»¬ëŸ¼ëª… ëŒ€ì‘)
            item_name = row.get('ìƒí’ˆ ì„ íƒ') or row.get('name')
            if not item_name: continue

            # 3. meta_dfì—ì„œ ID ì°¾ê¸°
            matched_row = all_df[all_df['Item_Name'] == item_name]
            
            if not matched_row.empty:
                item_id = str(matched_row.iloc[0]['item_id'])
                history.append({
                    'item_id': item_id,
                    'name': item_name,
                    'days_ago': days
                })
            else:
                # ë§¤í•‘ ì‹¤íŒ¨ ì‹œ ë¡œê¹… (UIì—ëŠ” ë„ìš°ì§€ ì•ŠìŒ)
                print(f"ë§¤í•‘ ì‹¤íŒ¨: {item_name}")
                
        return history
    except Exception as e:
        st.error(f"í˜ë¥´ì†Œë‚˜ ë¡œë“œ ì˜¤ë¥˜ ({filename}): {e}")
        return []

# ------------------------------------------------------------------
# 4. ë©”ì¸ ë¡œì§
# ------------------------------------------------------------------
def main():
    st.set_page_config(layout="wide", page_title="Recommendation Model A/B Test")
    st.title("ğŸ›ï¸ ì‡¼í•‘ íŒ¨í„´ ê¸°ë°˜ ì¶”ì²œ A/B Test")

    all_df, vocab_tis, vocab_sas = load_data()
    if all_df is None: return
    
    sas_model, tis_model, tis_maxlen, tis_timespan, safe_n = load_models()

    # UI í•„í„°ë§
    valid_tokens = [t for t, i in vocab_tis['token2id'].items() if i < safe_n]
    ui_df = all_df[all_df['item_id'].astype(str).isin(valid_tokens) & (all_df['purchase_count'] >= 10)].copy()

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'history' not in st.session_state: st.session_state['history'] = []

    # ---------------- Sidebar: ì…ë ¥ UI ----------------
    st.sidebar.header("ğŸ›’ êµ¬ë§¤ ì´ë ¥ êµ¬ì„±")
    
    # [1] í˜ë¥´ì†Œë‚˜ ì„ íƒ ì„¹ì…˜ (ì—…ë°ì´íŠ¸: í´ë” ìŠ¤ìº” ë° ì„ íƒ ì•ˆí•¨ ì˜µì…˜)
    st.sidebar.subheader("1. í˜ë¥´ì†Œë‚˜ ì„ íƒ")
    
    # personas í´ë” ìë™ ìƒì„± ë° íŒŒì¼ ìŠ¤ìº”
    persona_dir = os.path.join('data', 'personas')
    if not os.path.exists(persona_dir):
        os.makedirs(persona_dir, exist_ok=True)
        
    persona_files = [f for f in os.listdir(persona_dir) if f.endswith('.csv')]
    
    # 'ì„ íƒ ì•ˆ í•¨' ì˜µì…˜ì„ ë§¨ ì•ì— ì¶”ê°€
    options = ["ì§ì ‘ ì…ë ¥ (ì„ íƒ ì•ˆ í•¨)"] + persona_files
    
    selected_persona = st.sidebar.selectbox("í…ŒìŠ¤í„° ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”:", options)
    
    # íŒŒì¼ì„ ì„ íƒí–ˆì„ ë•Œë§Œ ë¡œë“œ ë²„íŠ¼ í‘œì‹œ
    if selected_persona != "ì§ì ‘ ì…ë ¥ (ì„ íƒ ì•ˆ í•¨)":
        if st.sidebar.button("ğŸ“‚ ì„ íƒí•œ í˜ë¥´ì†Œë‚˜ ë¶ˆëŸ¬ì˜¤ê¸°"):
            persona_history = load_persona_history(all_df, selected_persona)
            if persona_history:
                st.session_state['history'] = persona_history
                # ë‚ ì§œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ (ìµœì‹ ì´ ìœ„ë¡œ)
                st.session_state['history'].sort(key=lambda x: x['days_ago'], reverse=True)
                st.success(f"'{selected_persona}' ë¡œë“œ ì™„ë£Œ! ({len(persona_history)}ê°œ ì•„ì´í…œ)")
                st.session_state.pop('last_results', None) # ê¸°ì¡´ ê²°ê³¼ ì´ˆê¸°í™”
                st.rerun()

    st.sidebar.divider()
    
    # [2] ì§ì ‘ ì¶”ê°€ ì„¹ì…˜
    st.sidebar.subheader("2. ì•„ì´í…œ ì§ì ‘ ì¶”ê°€")
    if ui_df.empty:
        st.error("í‘œì‹œí•  ì•„ì´í…œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    l1 = st.sidebar.selectbox("ëŒ€ë¶„ë¥˜", sorted(ui_df['L1'].unique()))
    l2 = st.sidebar.selectbox("ì¤‘ë¶„ë¥˜", sorted(ui_df[ui_df['L1']==l1]['L2'].unique()))
    items = ui_df[(ui_df['L1']==l1) & (ui_df['L2']==l2)].sort_values(by='purchase_count', ascending=False)
    
    sel_item = st.sidebar.selectbox("ìƒí’ˆ ì„ íƒ", options=items.to_dict('records'), 
                                  format_func=lambda x: f"{x['Item_Name']} ({x['purchase_count']}íšŒ)")
    days = st.sidebar.number_input("ë©°ì¹  ì „ êµ¬ë§¤í–ˆë‚˜ìš”?", 0, 365, 0)
    
    if st.sidebar.button("â• ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€"):
        st.session_state['history'].append({
            'item_id': str(sel_item['item_id']), 
            'name': sel_item['Item_Name'], 
            'days_ago': days
        })
        st.session_state['history'].sort(key=lambda x: x['days_ago'], reverse=True)
        st.session_state.pop('last_results', None) # ê²°ê³¼ ì´ˆê¸°í™”
        st.rerun()

    if st.sidebar.button("ğŸ—‘ï¸ ì „ì²´ ì´ˆê¸°í™”"):
        st.session_state['history'] = []
        st.session_state.pop('last_results', None)
        st.rerun()

    # ---------------- Main: ì‹œí€€ìŠ¤ ê´€ë¦¬ ë° ì¶”ë¡  ----------------
    st.subheader("ğŸ“‹ í˜„ì¬ ì‹œí€€ìŠ¤ (TimeLine)")
    
    if not st.session_state['history']:
        st.info("ğŸ‘ˆ ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ í˜ë¥´ì†Œë‚˜ë¥¼ ì„ íƒí•˜ê±°ë‚˜, ì•„ì´í…œì„ ì§ì ‘ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    else:
        # [ê¸°ëŠ¥ ì¶”ê°€] ì‹œí€€ìŠ¤ ëª©ë¡ ë° ê°œë³„ ì‚­ì œ ê¸°ëŠ¥ êµ¬í˜„
        st.markdown("---")
        # enumerateë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸ë±ìŠ¤ë¥¼ í™•ë³´ (ì‚­ì œ ì‹œ í•„ìš”)
        for i, item in enumerate(st.session_state['history']):
            col1, col2, col3 = st.columns([1, 6, 1])
            
            # ì‹œê°„ í‘œì‹œ í…ìŠ¤íŠ¸
            if item['days_ago'] == 0:
                time_str = "ì˜¤ëŠ˜"
            else:
                time_str = f"{item['days_ago']}ì¼ ì „"
            
            with col1:
                st.caption(time_str)
            with col2:
                st.write(f"**{item['name']}**")
            with col3:
                # ì‚­ì œ ë²„íŠ¼: ê³ ìœ  keyë¥¼ ë¶€ì—¬í•˜ì—¬ ì¶©ëŒ ë°©ì§€
                if st.button("âŒ", key=f"del_{i}", help="ì´ ì•„ì´í…œë§Œ ì‚­ì œ"):
                    st.session_state['history'].pop(i)
                    st.session_state.pop('last_results', None) # ê²°ê³¼ ì´ˆê¸°í™”
                    st.rerun()
        st.markdown("---")
        
        # ì¶”ë¡  ë²„íŠ¼
        if st.button("ğŸš€ ì¶”ì²œ ê²°ê³¼ ë¹„êµ (Model A vs B)", type="primary"):
            if len(st.session_state['history']) < 2:
                st.warning("ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ ì•„ì´í…œì„ 2ê°œ ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("ë‘ ëª¨ë¸ì´ ì‹œí€€ìŠ¤ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    # --- ì…ë ¥ ë°ì´í„° ì¤€ë¹„ ---
                    t2i_tis = vocab_tis['token2id']
                    ids_tis, days_list = [], []
                    for h in st.session_state['history']:
                        if h['item_id'] in t2i_tis:
                            ids_tis.append(t2i_tis[h['item_id']])
                            days_list.append(h['days_ago'])
                    
                    t2i_sas = vocab_sas['token2id']
                    ids_sas = []
                    for h in st.session_state['history']:
                        if h['item_id'] in t2i_sas:
                            ids_sas.append(t2i_sas[h['item_id']])

                    if not ids_tis or not ids_sas:
                        st.error("ë§¤í•‘ ê°€ëŠ¥í•œ ì•„ì´í…œì´ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤.")
                        st.stop()

                    # --- ì¶”ë¡  ì‹¤í–‰ ---
                    
                    # [Model A] SASRec
                    # SASRecì€ ì‹œê°„ ì •ë³´ ì—†ì´ ì•„ì´í…œ ì‹œí€€ìŠ¤ë§Œ ì‚¬ìš©
                    seq_sas = ids_sas[-tis_maxlen:]
                    pad_len_sas = tis_maxlen - len(seq_sas)
                    input_sas = torch.LongTensor([[0]*pad_len_sas + seq_sas]).to(DEVICE)
                    len_sas = torch.LongTensor([tis_maxlen]).to(DEVICE) 
                    
                    topk_A_ids = []
                    if sas_model:
                        inter_sas = Interaction({'item_id_list': input_sas, 'item_length': len_sas})
                        scores_A = sas_model.full_sort_predict(inter_sas)
                        scores_A = scores_A.cpu().detach().numpy()[0]
                        topk_A_indices = np.argsort(scores_A)[::-1][:10]
                        topk_A_ids = topk_A_indices.tolist()

                    # [Model B] TiSASRec
                    # TiSASRecì€ ì•„ì´í…œ ì‹œí€€ìŠ¤ + ì‹œê°„ ê°„ê²©(Interval) ì •ë³´ ì‚¬ìš©
                    seq_tis = ids_tis[-tis_maxlen:]
                    d_seq = days_list[-tis_maxlen:]
                    pad_len_tis = tis_maxlen - len(seq_tis)
                    input_tis = torch.LongTensor([[0]*pad_len_tis + seq_tis]).to(DEVICE)
                    len_tis = torch.LongTensor([tis_maxlen]).to(DEVICE)
                    
                    # ì‹œê°„ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚° (utils.py ì˜ì¡´)
                    t_seq, t_mat = get_tisasrec_input(d_seq, tis_maxlen, tis_timespan)
                    
                    topk_B_ids = []
                    if tis_model:
                        inter_tis = Interaction({
                            'item_id_list': input_tis, 'item_length': len_tis,
                            'timestamp_list': t_seq.to(DEVICE), 'time_matrix': t_mat.to(DEVICE)
                        })
                        scores_B = tis_model.full_sort_predict(inter_tis)
                        scores_B = scores_B.cpu().detach().numpy()[0]
                        topk_B_indices = np.argsort(scores_B)[::-1][:10]
                        topk_B_ids = topk_B_indices.tolist()

                    # --- ê²°ê³¼ ì €ì¥ (ìˆœì„œ ëœë¤ ì„ê¸°: Blind Test) ---
                    results_list = [
                        {'ids': topk_A_ids, 'name': 'SASRec', 'type': 'A'},
                        {'ids': topk_B_ids, 'name': 'TiSASRec', 'type': 'B'}
                    ]
                    random.shuffle(results_list)
                    
                    st.session_state['last_results'] = results_list

    # ---------------- ê²°ê³¼ ì¶œë ¥ ----------------
    if 'last_results' in st.session_state:
        st.divider()
        st.subheader("ğŸ” ì¶”ì²œ ê²°ê³¼ ë¹„êµ (Blind Test)")
        
        results = st.session_state['last_results']
        res_left = results[0]
        res_right = results[1]
        
        # ID -> ì •ë³´ ë³€í™˜ í—¬í¼ í•¨ìˆ˜
        def get_item_info_detail(internal_id, model_type):
            if model_type == 'A':
                i2t = vocab_sas['id2token']
            else:
                i2t = vocab_tis['id2token']
                
            if internal_id in i2t:
                raw_id = i2t[internal_id]
                row = all_df[all_df['item_id'].astype(str) == raw_id]
                if not row.empty:
                    d = row.iloc[0]
                    return f"{d['L1']} > {d['L2']}", d['Item_Name']
                return "Unknown Cat", "Unknown Name"
            return "-", "-"

        c1, c2 = st.columns(2)
        
        # ì™¼ìª½ ê²°ê³¼
        with c1:
            st.info("### Option 1")
            for i, idx in enumerate(res_left['ids']):
                if idx == 0: continue
                cat, name = get_item_info_detail(idx, res_left['type'])
                st.markdown(f"**{i+1}. [{cat}]**\n{name}")
            
            if st.button("ğŸ‘ˆ Option 1 ì„ íƒ"):
                # ë¡œì»¬ CSV ì €ì¥
                save_log(res_left['name'], res_right['name'], "Option 1")
                st.balloons()
                st.success(f"ì„ íƒí•œ ëª¨ë¸ì€ [{res_left['name']}] ì…ë‹ˆë‹¤!")

        # ì˜¤ë¥¸ìª½ ê²°ê³¼
        with c2:
            st.success("### Option 2")
            for i, idx in enumerate(res_right['ids']):
                if idx == 0: continue
                cat, name = get_item_info_detail(idx, res_right['type'])
                st.markdown(f"**{i+1}. [{cat}]**\n{name}")
                
            if st.button("ğŸ‘‰ Option 2 ì„ íƒ"):
                # ë¡œì»¬ CSV ì €ì¥
                save_log(res_right['name'], res_left['name'], "Option 2")
                st.balloons()
                st.success(f"ì„ íƒí•œ ëª¨ë¸ì€ [{res_right['name']}] ì…ë‹ˆë‹¤!")

# CSV ì €ì¥ í•¨ìˆ˜
def save_log(winner_model, loser_model, choice_label):
    log_data = {
        "timestamp": pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),
        "winner": winner_model,
        "loser": loser_model,
        "user_choice": choice_label
    }
    file_path = 'ab_test_results.csv'
    df = pd.DataFrame([log_data])
    if not os.path.exists(file_path):
        df.to_csv(file_path, index=False, encoding='utf-8-sig')
    else:
        df.to_csv(file_path, index=False, header=False, mode='a', encoding='utf-8-sig')

if __name__ == "__main__":
    main()