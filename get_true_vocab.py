import sys
import os
import shutil
import torch
import pickle
from types import ModuleType

# ==============================================================================
# 1. [Mocking] (ê¸°ì¡´ê³¼ ë™ì¼)
# ==============================================================================
def mock_lib_with_class(module_name, class_names=[]):
    if module_name in sys.modules: return sys.modules[module_name]
    m = ModuleType(module_name)
    sys.modules[module_name] = m
    for cls_name in class_names:
        if not hasattr(m, cls_name): setattr(m, cls_name, type(cls_name, (object,), {}))
    return m

libs = ['kmeans_pytorch', 'lightgbm', 'xgboost', 'ray', 'hyperopt', 'colorama']
for lib in libs:
    mock_lib_with_class(lib)
    sys.modules[f"{lib}.sklearn"] = mock_lib_with_class(f"{lib}.sklearn")

if 'kmeans_pytorch' in sys.modules:
    sys.modules['kmeans_pytorch'].kmeans = lambda *args, **kwargs: (None, None)

mock_lib_with_class('recbole.model.general_recommender.ldiffrec', ['LDiffRec'])
mock_lib_with_class('recbole.model.general_recommender.diffrec', ['DiffRec'])

import tisasrec_local
sys.modules['TiSASRec'] = tisasrec_local

import recbole
if not hasattr(recbole, 'utils'):
    recbole.utils = ModuleType('recbole.utils')
    sys.modules['recbole.utils'] = recbole.utils
if not hasattr(recbole.utils, 'enum_type'):
    m_enum = ModuleType('recbole.utils.enum_type')
    sys.modules['recbole.utils.enum_type'] = m_enum
    recbole.utils.enum_type = m_enum
    class Dummy:
        def __init__(self, *args, **kwargs): pass
    for cls in ['ModelType', 'DataLoaderType', 'KGDataLoaderState', 'EvaluatorType', 'InputType', 'FeatureType']:
        setattr(m_enum, cls, Dummy)

# ==============================================================================
# 2. [í•µì‹¬] ë°ì´í„°ì…‹ ë³µì‚¬ ë° ì´ë¦„ ë³€ê²½ (ìºì‹œ ìš°íšŒ ì „ëµ)
# ==============================================================================
def prepare_new_dataset():
    # ì›ë³¸ (ê¸°ì¡´ì— ì“°ë˜ ê²ƒ)
    old_name = 'amazon-data'
    old_path = os.path.join('data', old_name, f'{old_name}.inter')
    
    # ì‹ ê·œ (ìƒˆë¡œìš´ ì´ë¦„)
    new_name = 'amazon-filtered'
    new_dir = os.path.join('data', new_name)
    new_path = os.path.join(new_dir, f'{new_name}.inter')
    
    # 1. ì›ë³¸ íŒŒì¼ ì°¾ê¸° (data/amazon-data.inter ë˜ëŠ” data/amazon-data/amazon-data.inter)
    if not os.path.exists(old_path):
        # í˜¹ì‹œ data í´ë” ë°”ë¡œ ë°‘ì— ìˆëŠ”ì§€ í™•ì¸
        alt_path = os.path.join('data', f'{old_name}.inter')
        if os.path.exists(alt_path):
            old_path = alt_path
        else:
            print(f"âŒ ì›ë³¸ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {old_path}")
            sys.exit(1)
            
    # 2. ìƒˆë¡œìš´ í´ë” ë§Œë“¤ê³  íŒŒì¼ ë³µì‚¬
    if not os.path.exists(new_dir):
        os.makedirs(new_dir)
        
    print(f"ğŸ“¦ ìºì‹œ íšŒí”¼ë¥¼ ìœ„í•´ ë°ì´í„° ë³µì‚¬ ì¤‘...")
    print(f"   {old_path} -> {new_path}")
    shutil.copy(old_path, new_path)
    
    return new_name

# ==============================================================================
# 3. ë§¤í•‘ ìƒì„± ë¡œì§
# ==============================================================================
from recbole.config import Config
from recbole.data import create_dataset

def extract_vocab_force():
    # 1. ìƒˆë¡œìš´ ì´ë¦„ì˜ ë°ì´í„°ì…‹ ì¤€ë¹„
    dataset_name = prepare_new_dataset()
    
    print("ğŸš€ RecBole ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘ (í•„í„°ë§ ì ìš©)...")
    
    # 2. ëª¨ë¸ ì„¤ì • ë¡œë“œ
    pth_path = 'data/TiSASRec-Nov-28-2025_09-45-58.pth'
    checkpoint = torch.load(pth_path, map_location='cpu', weights_only=False)
    saved_config = checkpoint['config']
    
    # 3. í•„í„°ë§ ì¡°ê±´ ì„¤ì • (5íšŒ ì´ìƒ)
    min_user = 5
    min_item = 5
    max_len = saved_config.get('MAX_ITEM_LIST_LENGTH', 50) if hasattr(saved_config, 'get') else 50

    config_dict = {
        'data_path': 'data/',           
        'dataset': dataset_name,  # 'amazon-filtered' (ìƒˆ ì´ë¦„!)
        'gpu_id': -1,                   
        'show_progress': False,
        
        # [ì¤‘ìš”] í•„í„°ë§ ì¡°ê±´
        'min_user_inter': min_user,
        'min_item_inter': min_item,
        'MAX_ITEM_LIST_LENGTH': max_len,
        
        'train_neg_sample_args': None, 
        'neg_sampling': None,
        'load_col': {'inter': ['user_id', 'item_id', 'timestamp']}
    }
    
    print(f"â„¹ï¸ í•„í„°ë§ ì¡°ê±´: User >= {min_user}, Item >= {min_item}")
    
    # 4. ë°ì´í„°ì…‹ ìƒì„±
    # ì´ë¦„ì´ ë°”ë€Œì—ˆìœ¼ë¯€ë¡œ RecBoleì€ ë¬´ì¡°ê±´ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ê³„ì‚°í•©ë‹ˆë‹¤.
    config = Config(model='SASRec', config_dict=config_dict)
    dataset = create_dataset(config)
    
    token2id = dataset.field2token_id['item_id']
    id2token = dataset.field2id_token['item_id']
    
    count = len(token2id)
    print("-" * 50)
    print(f"âœ… ìƒì„± ì™„ë£Œ!")
    print(f" - ë§¤í•‘ëœ ì•„ì´í…œ ê°œìˆ˜: {count}")
    
    target = 13225
    if abs(count - target) <= 1:
        print(f"ğŸ‰ [ì„±ê³µ] ëª¨ë¸ í•™ìŠµ ë°ì´í„° í¬ê¸°({target})ì™€ ì¼ì¹˜í•©ë‹ˆë‹¤!")
    else:
        print(f"âš ï¸ [ì£¼ì˜] ê°œìˆ˜ê°€ ë‹¤ë¦…ë‹ˆë‹¤ ({count} vs {target}).")
        print("   -> ì›ë³¸ ë°ì´í„° íŒŒì¼ ìì²´ê°€ í•™ìŠµ ë•Œì™€ ë‹¤ë¥¸ íŒŒì¼ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # 5. ì €ì¥
    output_path = "data/recbole_vocab.pkl"
    with open(output_path, "wb") as f:
        pickle.dump({'token2id': token2id, 'id2token': id2token}, f)
        
    print(f"âœ… ë§¤í•‘ íŒŒì¼ ì €ì¥ë¨: {output_path}")
    
    # ì²­ì†Œ (ë³µì‚¬í•œ íŒŒì¼ ì‚­ì œ)
    try:
        shutil.rmtree(os.path.join('data', dataset_name))
        print("ğŸ§¹ ì„ì‹œ ë°ì´í„° í´ë” ì •ë¦¬ ì™„ë£Œ")
    except:
        pass

if __name__ == "__main__":
    extract_vocab_force()